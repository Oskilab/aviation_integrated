{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "778cb5e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\11099\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import preprocess_helper\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import enchant\n",
    "checker = enchant.Dict(\"en_US\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88eecde7",
   "metadata": {},
   "source": [
    "***\n",
    "`FAA`, or `FAA.csv`, and `NASA`, or `nasa_abbr.csv`, contain two dictionaries of aviation acronyms used by FAA (Federal Aviation Administration) and NASA (National Aeronautics and Space Administration). Note that `CASA` dictionary is temporarily commented out due to the quality issue.\n",
    "\n",
    "`top_thirty`, or `FAA Core Airports 2014.csv` contains the tracon codes of thirty busiest **(or most popular? exact statistic?)** airports in 2014. We currently limit out analysis to these thirty airports. \n",
    "\n",
    "We are using the processed ASRS data by calling `load_asrs()` function in `preprocess_helper.py`. See line 173 in the [repo](https://github.com/Oskilab/aviation_integrated/blob/master/asrs_analysis/preprocess_helper.py). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "392e00c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\aviation_integrated\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3357: DtypeWarning: Columns (8,9,11,12,14,15,19,20,28,29,30,31,32,33,34,38,39,40,41,42,46,50,53,54,56,57,58,59,60,64,65,70,71,72,74,75,80,81,82,86,88,93,94,95,104) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "# Dictionaries of acronym\n",
    "# CASA = pd.read_csv('dictionaries/CASA.csv')\n",
    "FAA = pd.read_csv('dictionaries/FAA.csv')\n",
    "NASA = pd.read_csv('dictionaries/nasa_abbr.csv')\n",
    "top_thirty = pd.read_csv('dictionaries/FAA Core Airports 2014.csv')\n",
    "\n",
    "# Limit to top thirty airports\n",
    "ASRS = preprocess_helper.load_asrs(load_saved=True)\n",
    "top_thirty_bool = ASRS['tracon_code'].isin(top_thirty['tracon_key'])\n",
    "ASRS_30 = ASRS[top_thirty_bool]\n",
    "\n",
    "# Accident and incident counts of FAA and NTSB\n",
    "acc_inc = pd.read_csv(r\"E:\\aviation_integrated\\results\\combined_vol_incident.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f8d161",
   "metadata": {},
   "source": [
    "***\n",
    "Here are some utility functions that help us count acronyms in the reports of ASRS in different ways. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f29d3cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions used for counting the acronyms in ASRS data\n",
    "\n",
    "# Check if a word is spelled correctly (OBSOLETE)\n",
    "# def spell_check(word):\n",
    "#     return checker.check(word)\n",
    " \n",
    "def count_acronyms(text, acronym):\n",
    "    \"\"\"\n",
    "    Compute the frequency of all acronyms shown and the number of unique acronyms shown\n",
    "    in the text paragraph according to a specified dictionary.\n",
    "    \n",
    "    Input arguments:\n",
    "    TEXT - String. The text pargraph in which we find and count the acronyms.\n",
    "    ACRONYMS - List of strings. Each entry is an acronym. \n",
    "    \n",
    "    Returns:\n",
    "    TOTAL - integer, frequency of all the acronyms shown in TEXT.\n",
    "    UNIQUE - integer, the number of unique acronyms shown in TEXT\n",
    "    \"\"\"   \n",
    "    # assert correct types of input arguments\n",
    "    \n",
    "    # create a dictionary containing the counts of distinct words\n",
    "    all_words = text.lower().split()\n",
    "    all_words = [x.strip('{[(,:.') for x in all_words]\n",
    "    words_count = Counter(all_words)\n",
    "    \n",
    "    text_acronym = [word for word in words_count.keys() if word in acronym]\n",
    "    unique = len(text_acronym)\n",
    "    total = np.sum([words_count[word] for word in text_acronym])   \n",
    "        \n",
    "    return total, unique\n",
    "\n",
    "# Testing count_acronyms\n",
    "sample_text = \"Go bears, we bears will beat stanford oh yeah let's go.\"\n",
    "acronyms = ['go', 'bears', 'bear']\n",
    "\n",
    "assert count_acronyms(sample_text, acronyms) == (4, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad49c04-5de3-4021-bc1d-0638e0ee82f3",
   "metadata": {},
   "source": [
    "***\n",
    "We clean the dictionaries here. Note that `CASA` dictionary is temporarily commented out due to the quality issue.\n",
    "\n",
    "We remove the stop words, such as *me*, *she*, and *am*, from the acronyms to avoid confusion. Suppose *me* is an acronym, then how can we know whether *me* in the text represents a stop word or an acronym?\n",
    "\n",
    "Note that we temporarily discard removing the spelling check. By manual examination of the text, we notice that most acronyms that pass the spelling check are not used as normal English words in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2f26c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the field of acronyms\n",
    "\n",
    "# CASA['acronym'] = CASA['acronym'].str.strip().str.lower()\n",
    "# CASA['acronym'] = CASA['acronym'].str.replace(r'\\(.+\\)', '', regex=True)\n",
    "# CASA.drop_duplicates([\"acronym\"], inplace=True, keep='first')\n",
    "# CASA_cleaned = CASA[['acronym']]\n",
    "\n",
    "FAA['acronym'] = FAA['acronym'].str.strip().str.lower()\n",
    "FAA.drop_duplicates([\"acronym\"], inplace=True, keep='first')\n",
    "FAA_cleaned = FAA[['acronym']]\n",
    "\n",
    "NASA['acronym'] = NASA['acronym'].str.strip().str.lower()\n",
    "NASA.drop_duplicates([\"acronym\"], inplace=True, keep='first')\n",
    "NASA_cleaned = NASA[['acronym']]\n",
    "\n",
    "top_thirty['tracon_key'] = top_thirty['tracon_key'].str.strip().str.upper()\n",
    "top_thirty.drop_duplicates([\"tracon_key\"], inplace=True, keep='first')\n",
    "top_thirty_cleaned = top_thirty[['tracon_key']]\n",
    "\n",
    "# Remove stop words in the dictionaries\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# bool_index = CASA_cleaned.isin(stop_words)['acronym'].values\n",
    "# CASA_cleaned = CASA_cleaned[~bool_index]\n",
    "\n",
    "bool_index = FAA_cleaned.isin(stop_words)['acronym'].values\n",
    "FAA_cleaned = FAA_cleaned[~bool_index]\n",
    "\n",
    "bool_index = NASA_cleaned.isin(stop_words)['acronym'].values\n",
    "NASA_cleaned = NASA_cleaned[~bool_index]\n",
    "\n",
    "# Filter out the words passing the spelling check (OBSOLETE)\n",
    "# bool_index = np.array(list(map(spell_check, list(CASA_cleaned['acronym'].values))))\n",
    "# CASA_cleaned = CASA_cleaned[~bool_index]\n",
    "\n",
    "# bool_index = np.array(list(map(spell_check, list(FAA_cleaned['acronym'].values))))\n",
    "# FAA_cleaned = FAA_cleaned[~bool_index]\n",
    "\n",
    "# bool_index = np.array(list(map(spell_check, list(NASA_cleaned['acronym'].values))))\n",
    "# NASA_cleaned = NASA_cleaned[~bool_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f92254",
   "metadata": {},
   "source": [
    "***\n",
    "## Create Master Key\n",
    "\n",
    "`master_key` contains all possible combinations of `tracon` (top thirty airports), `year` (1988 - 2019), and `month` (January to December). It serves as a standard and exhausted key which helps us find the indices of `(tracon, year, month)`  that do not have any observation in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d231e289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tracon</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATL</td>\n",
       "      <td>1988</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL</td>\n",
       "      <td>1988</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATL</td>\n",
       "      <td>1988</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATL</td>\n",
       "      <td>1988</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATL</td>\n",
       "      <td>1988</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11515</th>\n",
       "      <td>TPA</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11516</th>\n",
       "      <td>TPA</td>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11517</th>\n",
       "      <td>TPA</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11518</th>\n",
       "      <td>TPA</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11519</th>\n",
       "      <td>TPA</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11520 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      tracon  year  month\n",
       "0        ATL  1988      1\n",
       "1        ATL  1988      2\n",
       "2        ATL  1988      3\n",
       "3        ATL  1988      4\n",
       "4        ATL  1988      5\n",
       "...      ...   ...    ...\n",
       "11515    TPA  2019      8\n",
       "11516    TPA  2019      9\n",
       "11517    TPA  2019     10\n",
       "11518    TPA  2019     11\n",
       "11519    TPA  2019     12\n",
       "\n",
       "[11520 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date = pd.date_range(start = '1/1/1988', end = '12/31/2019', freq = 'M')\n",
    "date_df = pd.DataFrame(data = {'year': date.year, 'month': date.month})\n",
    "master_key = top_thirty.merge(date_df, how = 'cross')\n",
    "master_key = master_key.drop('ATADS_Type', axis = 1)\n",
    "master_key = master_key.rename({'tracon_key': 'tracon'}, axis = 1)\n",
    "master_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45c8faaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_key.to_csv(\"quality_check/master_key.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae7d3a8",
   "metadata": {},
   "source": [
    "***\n",
    "## Merge FAA/NTSB with master key\n",
    "\n",
    "We merge the data of accidents and incidents from FAA and NTSB with `master_key` we created above. We can easily see the advantage of using `master_key` to find the indices that have no observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1861e98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit NTSB/FAA to top 30\n",
    "acc_inc_bool = acc_inc['airport_code'].isin(top_thirty['tracon_key'])\n",
    "acc_inc_30 = acc_inc.loc[acc_inc_bool]\n",
    "acc_inc_30 = acc_inc_30.drop(\"Unnamed: 0\", axis = 1)\n",
    "acc_inc_30 = acc_inc_30.rename({'airport_code': 'tracon'}, axis = 1)\n",
    "acc_inc_30.to_csv('quality_check/acc_inc_30.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6b406b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tracon</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>ntsb_incidents</th>\n",
       "      <th>ntsb_accidents</th>\n",
       "      <th>faa_incidents</th>\n",
       "      <th>faa_ntsb_overlap</th>\n",
       "      <th>NTSB_FAA_incidents_total</th>\n",
       "      <th>NTSB_FAA_incidents_total_nodups</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATL</td>\n",
       "      <td>1988</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL</td>\n",
       "      <td>1988</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATL</td>\n",
       "      <td>1988</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATL</td>\n",
       "      <td>1988</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATL</td>\n",
       "      <td>1988</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11515</th>\n",
       "      <td>TPA</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11516</th>\n",
       "      <td>TPA</td>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11517</th>\n",
       "      <td>TPA</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11518</th>\n",
       "      <td>TPA</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11519</th>\n",
       "      <td>TPA</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11520 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      tracon  year  month  ntsb_incidents  ntsb_accidents  faa_incidents  \\\n",
       "0        ATL  1988      1             0.0             0.0            1.0   \n",
       "1        ATL  1988      2             NaN             NaN            NaN   \n",
       "2        ATL  1988      3             1.0             0.0            4.0   \n",
       "3        ATL  1988      4             1.0             0.0            0.0   \n",
       "4        ATL  1988      5             0.0             2.0            0.0   \n",
       "...      ...   ...    ...             ...             ...            ...   \n",
       "11515    TPA  2019      8             0.0             1.0            0.0   \n",
       "11516    TPA  2019      9             0.0             0.0            2.0   \n",
       "11517    TPA  2019     10             NaN             NaN            NaN   \n",
       "11518    TPA  2019     11             NaN             NaN            NaN   \n",
       "11519    TPA  2019     12             NaN             NaN            NaN   \n",
       "\n",
       "       faa_ntsb_overlap  NTSB_FAA_incidents_total  \\\n",
       "0                   0.0                       1.0   \n",
       "1                   NaN                       NaN   \n",
       "2                   1.0                       5.0   \n",
       "3                   0.0                       1.0   \n",
       "4                   0.0                       2.0   \n",
       "...                 ...                       ...   \n",
       "11515               0.0                       1.0   \n",
       "11516               0.0                       2.0   \n",
       "11517               NaN                       NaN   \n",
       "11518               NaN                       NaN   \n",
       "11519               NaN                       NaN   \n",
       "\n",
       "       NTSB_FAA_incidents_total_nodups  \n",
       "0                                  1.0  \n",
       "1                                  NaN  \n",
       "2                                  4.0  \n",
       "3                                  1.0  \n",
       "4                                  2.0  \n",
       "...                                ...  \n",
       "11515                              1.0  \n",
       "11516                              2.0  \n",
       "11517                              NaN  \n",
       "11518                              NaN  \n",
       "11519                              NaN  \n",
       "\n",
       "[11520 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faa_ntsb_merge = master_key.merge(acc_inc_30, left_on=['tracon', 'year', 'month'], right_on=['tracon', 'year', 'month'], how='left')\n",
    "faa_ntsb_merge.to_csv('quality_check/merge_acc_inc.csv')\n",
    "faa_ntsb_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3cf6c5",
   "metadata": {},
   "source": [
    "**Note**: Perhaps use an indicator column that marks the index the missing data with ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fe4e57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "faa_ntsb_merge = faa_ntsb_merge.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c5d94c",
   "metadata": {},
   "source": [
    "***\n",
    "## Moving average of ASRS\n",
    "\n",
    "Here we utilize the idea of *moving average* to create aggregated statistics of acronym counts in ASRS data. The goal is to study the relationship between the acronym counts of past ASRS reports and the future incident and accident counts.\n",
    "\n",
    "We first group all the observations in ASRS by `(tracon, year, month)`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "014a20a8-0309-4735-9a49-577b9467480a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collapse ASRS by [year, month, tracon_code]\n",
    "asrs_collapse = ASRS_30.groupby(['tracon_code', 'year', 'month'])[['narrative']].agg(lambda x: x.str.cat(sep=' ')).reset_index()\n",
    "asrs_collapse['num_obs'] = ASRS_30.groupby(['year', 'month', 'tracon_code']).size().values\n",
    "asrs_collapse['AtcAdvisoryMultCount'] = ASRS_30.groupby(['year', 'month', 'tracon_code'])['AtcAdvisoryMultCount'].sum().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35604fbf-e1f8-4d56-9809-727286f88923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tracon_code</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>narrative</th>\n",
       "      <th>num_obs</th>\n",
       "      <th>AtcAdvisoryMultCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATL</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>apching the atl area a solid line of thunderst...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>established on ils rwy 27l atl on a 12 mile fi...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATL</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>f o was flying the acft and assigned a 060 deg...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATL</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>tca was inadvertently entered at 11500 in uppe...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATL</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>while being vectored for apch to rwy 9r atc di...</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tracon_code    year  month  \\\n",
       "0         ATL  1988.0    1.0   \n",
       "1         ATL  1988.0    2.0   \n",
       "2         ATL  1988.0    3.0   \n",
       "3         ATL  1988.0    4.0   \n",
       "4         ATL  1988.0    6.0   \n",
       "\n",
       "                                           narrative  num_obs  \\\n",
       "0  apching the atl area a solid line of thunderst...        3   \n",
       "1  established on ils rwy 27l atl on a 12 mile fi...        5   \n",
       "2  f o was flying the acft and assigned a 060 deg...        1   \n",
       "3  tca was inadvertently entered at 11500 in uppe...        5   \n",
       "4  while being vectored for apch to rwy 9r atc di...        7   \n",
       "\n",
       "   AtcAdvisoryMultCount  \n",
       "0                     3  \n",
       "1                     5  \n",
       "2                     1  \n",
       "3                     6  \n",
       "4                     8  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asrs_collapse.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c98119-4786-4333-96a9-1f5e4b6ac3f8",
   "metadata": {},
   "source": [
    "Then we merge the aggregated ASRS data with master key to find the indices that do not have observations and fill in the missing values corresponding to these indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2b38c32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>tracon</th>\n",
       "      <th>narrative</th>\n",
       "      <th>AtcAdvisoryMultCount</th>\n",
       "      <th>num_obs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1988</td>\n",
       "      <td>1</td>\n",
       "      <td>ATL</td>\n",
       "      <td>apching the atl area a solid line of thunderst...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1988</td>\n",
       "      <td>2</td>\n",
       "      <td>ATL</td>\n",
       "      <td>established on ils rwy 27l atl on a 12 mile fi...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1988</td>\n",
       "      <td>3</td>\n",
       "      <td>ATL</td>\n",
       "      <td>f o was flying the acft and assigned a 060 deg...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1988</td>\n",
       "      <td>4</td>\n",
       "      <td>ATL</td>\n",
       "      <td>tca was inadvertently entered at 11500 in uppe...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1988</td>\n",
       "      <td>5</td>\n",
       "      <td>ATL</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1988</td>\n",
       "      <td>6</td>\n",
       "      <td>ATL</td>\n",
       "      <td>while being vectored for apch to rwy 9r atc di...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1988</td>\n",
       "      <td>7</td>\n",
       "      <td>ATL</td>\n",
       "      <td>during enrte portion of flt we were assigned a...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1988</td>\n",
       "      <td>8</td>\n",
       "      <td>ATL</td>\n",
       "      <td>at about 200 agl on final apch to rwy 27l at a...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1988</td>\n",
       "      <td>9</td>\n",
       "      <td>ATL</td>\n",
       "      <td>mlg x was dsnded to 12000 mlg x read back 1000...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1988</td>\n",
       "      <td>10</td>\n",
       "      <td>ATL</td>\n",
       "      <td>at 13000 level flt 250 kts i asked the f o to ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month tracon                                          narrative  \\\n",
       "0  1988      1    ATL  apching the atl area a solid line of thunderst...   \n",
       "1  1988      2    ATL  established on ils rwy 27l atl on a 12 mile fi...   \n",
       "2  1988      3    ATL  f o was flying the acft and assigned a 060 deg...   \n",
       "3  1988      4    ATL  tca was inadvertently entered at 11500 in uppe...   \n",
       "4  1988      5    ATL                                                      \n",
       "5  1988      6    ATL  while being vectored for apch to rwy 9r atc di...   \n",
       "6  1988      7    ATL  during enrte portion of flt we were assigned a...   \n",
       "7  1988      8    ATL  at about 200 agl on final apch to rwy 27l at a...   \n",
       "8  1988      9    ATL  mlg x was dsnded to 12000 mlg x read back 1000...   \n",
       "9  1988     10    ATL  at 13000 level flt 250 kts i asked the f o to ...   \n",
       "\n",
       "   AtcAdvisoryMultCount  num_obs  \n",
       "0                   3.0      3.0  \n",
       "1                   5.0      5.0  \n",
       "2                   1.0      1.0  \n",
       "3                   6.0      5.0  \n",
       "4                   0.0      0.0  \n",
       "5                   8.0      7.0  \n",
       "6                   6.0      5.0  \n",
       "7                   3.0      2.0  \n",
       "8                   5.0      3.0  \n",
       "9                   1.0      1.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge ASRS with master key\n",
    "asrs_merge = master_key.merge(asrs_collapse, left_on=['tracon', 'year', 'month'], right_on=['tracon_code', 'year', 'month'], how='left')\n",
    "asrs_merge = asrs_merge.loc[:, ['year', 'month', 'tracon', 'narrative', 'AtcAdvisoryMultCount', 'num_obs']]\n",
    "asrs_merge['narrative'] = asrs_merge['narrative'].fillna('')\n",
    "asrs_merge = asrs_merge.fillna(0)\n",
    "asrs_merge.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4996027-6133-4041-a345-40e357f78bc9",
   "metadata": {},
   "source": [
    "The next code cell is a key part. We first split the ASRS and FAA/NTSB data by `tracon`. We presume that the past reports from a certain airport will only affect the future accident and incidents of the same airport. **Possible to affect other airports as well?**\n",
    "\n",
    "Then, we use a moving window with customized length (`window_len`) to scan over the ASRS data and create different groups of data. The stride is 1 (**customize it?**).  In each group, we concatenate all the text reports to a single pargraph and then count the acronyms in the paragraph. For each count statistic, such as `FAA_total`, we create the sum and average of it of all the observations in the group. The average will be per observation. **Do we need the average of observations?**\n",
    "\n",
    "If a group does not have the number of observations which is equal to `window_len`, then we use 0 for all the aggregated count statistics. \n",
    "\n",
    "Finally, we merge all the aggregated count statistics with FAA/NTSB incident and accident data with customized offset or lag (`lag`). We expect the effect of past ASRS reports will not be immediately shown by the future FAA/NTSB incident and accident counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3665a097-b256-47f9-ba8a-048ce75170c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:/Anaconda/envs/aviation_integrated/Library/bin/xpython:111: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "D:/Anaconda/envs/aviation_integrated/Library/bin/xpython:47: RuntimeWarning: invalid value encountered in double_scalars\n",
      "D:/Anaconda/envs/aviation_integrated/Library/bin/xpython:52: RuntimeWarning: invalid value encountered in double_scalars\n",
      "D:/Anaconda/envs/aviation_integrated/Library/bin/xpython:57: RuntimeWarning: invalid value encountered in double_scalars\n",
      "D:/Anaconda/envs/aviation_integrated/Library/bin/xpython:59: RuntimeWarning: invalid value encountered in double_scalars\n",
      "D:/Anaconda/envs/aviation_integrated/Library/bin/xpython:64: RuntimeWarning: invalid value encountered in double_scalars\n",
      "D:/Anaconda/envs/aviation_integrated/Library/bin/xpython:66: RuntimeWarning: invalid value encountered in double_scalars\n",
      "D:/Anaconda/envs/aviation_integrated/Library/bin/xpython:71: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "window_len = 6\n",
    "lag = 1\n",
    "\n",
    "# split the data by the tracon code\n",
    "asrs_splits = [asrs_merge[asrs_merge['tracon'] == tracon] for tracon in top_thirty['tracon_key']] # can be optimized\n",
    "faa_ntsb_splits = [faa_ntsb_merge[faa_ntsb_merge['tracon'] == tracon] for tracon in top_thirty['tracon_key']] # can be optimized\n",
    "final = []\n",
    "\n",
    "for i in range(len(asrs_splits)):\n",
    "    asrs = asrs_splits[i].reset_index().drop('index', axis = 1)\n",
    "    faa_ntsb = faa_ntsb_splits[i].reset_index().drop('index', axis = 1)\n",
    "    \n",
    "    # compute moving average of ASRS \n",
    "    windows = asrs.rolling(window = window_len, min_periods=window_len)\n",
    "    num_obs_sum = []\n",
    "    #num_obs_avg = []\n",
    "    num_word_sum = []\n",
    "    num_word_avg = []\n",
    "    num_unique_word_sum = []\n",
    "    num_unique_word_avg = []\n",
    "    FAA_total_sum = []\n",
    "    FAA_total_avg = []\n",
    "    FAA_unique_sum = []\n",
    "    FAA_unique_avg = []\n",
    "    NASA_total_sum = []\n",
    "    NASA_total_avg = []\n",
    "    NASA_unique_sum = []\n",
    "    NASA_unique_avg = []\n",
    "    AtcAdvisoryMultCount_sum = []\n",
    "    AtcAdvisoryMultCount_avg = []\n",
    "\n",
    "\n",
    "    for window in windows:\n",
    "        size = window.shape[0]\n",
    "\n",
    "        # create a dictionary of counts of words\n",
    "        text_concate = window['narrative'].str.cat(sep=' ')\n",
    "        \n",
    "        # number of observations\n",
    "        num_obs = window['num_obs'].sum()\n",
    "        num_obs_sum.append(num_obs)\n",
    "        # num_obs_avg.append(num_obs / size)\n",
    "        \n",
    "        # number of words\n",
    "        num_word = len(text_concate.split())\n",
    "        num_word_sum.append(num_word)\n",
    "        num_word_avg.append(num_word / num_obs)\n",
    "\n",
    "        # number of unique words\n",
    "        num_unique_word = len(set(text_concate.split()))\n",
    "        num_unique_word_sum.append(num_unique_word)\n",
    "        num_unique_word_avg.append(num_unique_word / num_obs)\n",
    "\n",
    "        # number of FAA acronyms\n",
    "        FAA_total, FAA_unique = count_acronyms(text_concate, FAA_cleaned['acronym'].values)\n",
    "        FAA_total_sum.append(FAA_total)\n",
    "        FAA_total_avg.append(FAA_total / num_obs)\n",
    "        FAA_unique_sum.append(FAA_unique)\n",
    "        FAA_unique_avg.append(FAA_unique / num_obs)\n",
    "\n",
    "        # number of NASA acronyms\n",
    "        NASA_total, NASA_unique = count_acronyms(text_concate, NASA_cleaned['acronym'].values)\n",
    "        NASA_total_sum.append(NASA_total)\n",
    "        NASA_total_avg.append(NASA_total / num_obs)\n",
    "        NASA_unique_sum.append(NASA_unique)\n",
    "        NASA_unique_avg.append(NASA_unique / num_obs)\n",
    "\n",
    "        # number of atcadvisory splits\n",
    "        num_splits = window['AtcAdvisoryMultCount'].sum()\n",
    "        AtcAdvisoryMultCount_sum.append(num_splits)\n",
    "        AtcAdvisoryMultCount_avg.append(num_splits / num_obs)\n",
    "    \n",
    "    # convert list to numpy arrays\n",
    "    num_obs_sum = np.array(num_obs_sum)\n",
    "    #num_obs_avg = np.array(num_obs_avg)\n",
    "    num_word_sum = np.array(num_word_sum)\n",
    "    num_word_avg =  np.array(num_word_avg)\n",
    "    num_unique_word_sum = np.array(num_unique_word_sum)\n",
    "    num_unique_word_avg = np.array(num_unique_word_avg)\n",
    "    FAA_total_sum = np.array(FAA_total_sum)\n",
    "    FAA_total_avg = np.array(FAA_total_avg)\n",
    "    FAA_unique_sum = np.array(FAA_unique_sum)\n",
    "    FAA_unique_avg = np.array(FAA_unique_avg)\n",
    "    NASA_total_sum = np.array(NASA_total_sum)\n",
    "    NASA_total_avg = np.array(NASA_total_avg)\n",
    "    NASA_unique_sum = np.array(NASA_unique_sum)\n",
    "    NASA_unique_avg = np.array(NASA_unique_avg)\n",
    "    AtcAdvisoryMultCount_sum = np.array(AtcAdvisoryMultCount_sum)\n",
    "    AtcAdvisoryMultCount_avg = np.array(AtcAdvisoryMultCount_avg)\n",
    "      \n",
    "    # add the counts to the dataframe\n",
    "    asrs_moving = asrs.drop(['narrative', 'AtcAdvisoryMultCount'], axis = 1)\n",
    "    asrs_moving['num_obs_sum'] = num_obs_sum\n",
    "    #asrs_moving['num_obs_avg'] = num_obs_avg\n",
    "    asrs_moving['num_word_sum'] = num_word_sum\n",
    "    asrs_moving['num_word_avg'] = num_word_avg\n",
    "    asrs_moving['num_unique_word_sum'] = num_unique_word_sum \n",
    "    asrs_moving['num_unique_word_avg'] = num_unique_word_avg \n",
    "    asrs_moving['FAA_total_sum'] = FAA_total_sum\n",
    "    asrs_moving['FAA_total_avg'] = FAA_total_avg\n",
    "    asrs_moving['FAA_unique_sum'] = FAA_unique_sum\n",
    "    asrs_moving['FAA_unique_avg'] = FAA_unique_avg\n",
    "    asrs_moving['NASA_total_sum'] = NASA_total_sum\n",
    "    asrs_moving['NASA_total_avg'] = NASA_total_avg\n",
    "    asrs_moving['NASA_unique_sum'] = NASA_unique_sum\n",
    "    asrs_moving['NASA_unique_avg'] = NASA_unique_avg\n",
    "    asrs_moving['AtcAdvisoryMultCount_sum'] = AtcAdvisoryMultCount_sum\n",
    "    asrs_moving['AtcAdvisoryMultCount_avg'] = AtcAdvisoryMultCount_avg\n",
    "    \n",
    "    # insert empty rows at the beginning for lagging\n",
    "    empty_row_df = pd.DataFrame(data = [pd.Series(index=asrs.columns) for _ in range(lag)])\n",
    "    empty_row_df = empty_row_df.drop('tracon', axis = 1)   \n",
    "    \n",
    "    # merge the moving averages of ASRS with FAA+NTSB \n",
    "    asrs_moving = pd.concat([empty_row_df, asrs_moving])\n",
    "    asrs_moving = asrs_moving.drop(['year', 'month', 'tracon'], axis = 1)\n",
    "    asrs_moving = asrs_moving.reset_index().drop('index', axis = 1)\n",
    "    merge_df = pd.concat([faa_ntsb, asrs_moving], axis = 1)\n",
    "    final.append(merge_df)\n",
    "\n",
    "final_df = pd.concat(final).reset_index().drop(['index', 'AtcAdvisoryMultCount', 'narrative', 'num_obs'], axis = 1)\n",
    "final_df.insert(9, \"num_obs\", asrs_merge['num_obs'])\n",
    "final_df.to_csv('quality_check/final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "601549d9-a4c2-4996-a7d2-2d550ea835b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tracon</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>ntsb_incidents</th>\n",
       "      <th>ntsb_accidents</th>\n",
       "      <th>faa_incidents</th>\n",
       "      <th>faa_ntsb_overlap</th>\n",
       "      <th>NTSB_FAA_incidents_total</th>\n",
       "      <th>NTSB_FAA_incidents_total_nodups</th>\n",
       "      <th>num_obs</th>\n",
       "      <th>...</th>\n",
       "      <th>FAA_total_sum</th>\n",
       "      <th>FAA_total_avg</th>\n",
       "      <th>FAA_unique_sum</th>\n",
       "      <th>FAA_unique_avg</th>\n",
       "      <th>NASA_total_sum</th>\n",
       "      <th>NASA_total_avg</th>\n",
       "      <th>NASA_unique_sum</th>\n",
       "      <th>NASA_unique_avg</th>\n",
       "      <th>AtcAdvisoryMultCount_sum</th>\n",
       "      <th>AtcAdvisoryMultCount_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATL</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>134.0</td>\n",
       "      <td>44.666667</td>\n",
       "      <td>46.0</td>\n",
       "      <td>15.333333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATL</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>106.0</td>\n",
       "      <td>13.250000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.375000</td>\n",
       "      <td>334.0</td>\n",
       "      <td>41.750000</td>\n",
       "      <td>84.0</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATL</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>136.0</td>\n",
       "      <td>15.111111</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.111111</td>\n",
       "      <td>475.0</td>\n",
       "      <td>52.777778</td>\n",
       "      <td>96.0</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATL</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>140.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>481.0</td>\n",
       "      <td>34.357143</td>\n",
       "      <td>99.0</td>\n",
       "      <td>7.071429</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11545</th>\n",
       "      <td>TPA</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11546</th>\n",
       "      <td>TPA</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11547</th>\n",
       "      <td>TPA</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11548</th>\n",
       "      <td>TPA</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11549</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11550 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      tracon    year  month  ntsb_incidents  ntsb_accidents  faa_incidents  \\\n",
       "0        ATL  1988.0    1.0             0.0             0.0            1.0   \n",
       "1        ATL  1988.0    2.0             0.0             0.0            0.0   \n",
       "2        ATL  1988.0    3.0             1.0             0.0            4.0   \n",
       "3        ATL  1988.0    4.0             1.0             0.0            0.0   \n",
       "4        ATL  1988.0    5.0             0.0             2.0            0.0   \n",
       "...      ...     ...    ...             ...             ...            ...   \n",
       "11545    TPA  2019.0    9.0             0.0             0.0            2.0   \n",
       "11546    TPA  2019.0   10.0             0.0             0.0            0.0   \n",
       "11547    TPA  2019.0   11.0             0.0             0.0            0.0   \n",
       "11548    TPA  2019.0   12.0             0.0             0.0            0.0   \n",
       "11549    NaN     NaN    NaN             NaN             NaN            NaN   \n",
       "\n",
       "       faa_ntsb_overlap  NTSB_FAA_incidents_total  \\\n",
       "0                   0.0                       1.0   \n",
       "1                   0.0                       0.0   \n",
       "2                   1.0                       5.0   \n",
       "3                   0.0                       1.0   \n",
       "4                   0.0                       2.0   \n",
       "...                 ...                       ...   \n",
       "11545               0.0                       2.0   \n",
       "11546               0.0                       0.0   \n",
       "11547               0.0                       0.0   \n",
       "11548               0.0                       0.0   \n",
       "11549               NaN                       NaN   \n",
       "\n",
       "       NTSB_FAA_incidents_total_nodups  num_obs  ...  FAA_total_sum  \\\n",
       "0                                  1.0      3.0  ...            NaN   \n",
       "1                                  0.0      5.0  ...           32.0   \n",
       "2                                  4.0      1.0  ...          106.0   \n",
       "3                                  1.0      5.0  ...          136.0   \n",
       "4                                  2.0      0.0  ...          140.0   \n",
       "...                                ...      ...  ...            ...   \n",
       "11545                              2.0      NaN  ...            1.0   \n",
       "11546                              0.0      NaN  ...            1.0   \n",
       "11547                              0.0      NaN  ...            1.0   \n",
       "11548                              0.0      NaN  ...            1.0   \n",
       "11549                              NaN      NaN  ...            0.0   \n",
       "\n",
       "       FAA_total_avg  FAA_unique_sum  FAA_unique_avg  NASA_total_sum  \\\n",
       "0                NaN             NaN             NaN             NaN   \n",
       "1          10.666667             7.0        2.333333           134.0   \n",
       "2          13.250000            19.0        2.375000           334.0   \n",
       "3          15.111111            19.0        2.111111           475.0   \n",
       "4          10.000000            21.0        1.500000           481.0   \n",
       "...              ...             ...             ...             ...   \n",
       "11545       0.500000             1.0        0.500000             0.0   \n",
       "11546       0.500000             1.0        0.500000             0.0   \n",
       "11547       0.500000             1.0        0.500000             0.0   \n",
       "11548       0.500000             1.0        0.500000             0.0   \n",
       "11549            NaN             0.0             NaN             0.0   \n",
       "\n",
       "       NASA_total_avg  NASA_unique_sum  NASA_unique_avg  \\\n",
       "0                 NaN              NaN              NaN   \n",
       "1           44.666667             46.0        15.333333   \n",
       "2           41.750000             84.0        10.500000   \n",
       "3           52.777778             96.0        10.666667   \n",
       "4           34.357143             99.0         7.071429   \n",
       "...               ...              ...              ...   \n",
       "11545        0.000000              0.0         0.000000   \n",
       "11546        0.000000              0.0         0.000000   \n",
       "11547        0.000000              0.0         0.000000   \n",
       "11548        0.000000              0.0         0.000000   \n",
       "11549             NaN              0.0              NaN   \n",
       "\n",
       "       AtcAdvisoryMultCount_sum  AtcAdvisoryMultCount_avg  \n",
       "0                           NaN                       NaN  \n",
       "1                           3.0                  1.000000  \n",
       "2                           8.0                  1.000000  \n",
       "3                           9.0                  1.000000  \n",
       "4                          15.0                  1.071429  \n",
       "...                         ...                       ...  \n",
       "11545                       2.0                  1.000000  \n",
       "11546                       2.0                  1.000000  \n",
       "11547                       2.0                  1.000000  \n",
       "11548                       2.0                  1.000000  \n",
       "11549                       0.0                       NaN  \n",
       "\n",
       "[11550 rows x 25 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0a56a47-ccee-41ab-8275-c1fe6e021d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "asrs_merge.to_csv(\"quality_check/asrs_merge.csv\")\n",
    "asrs_moving.to_csv(\"quality_check/asrs_moving.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4cf50d",
   "metadata": {},
   "source": [
    "# Quality check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86142ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(\"quality_check\")\n",
    "except OSError as error:\n",
    "    print(error)\n",
    "\n",
    "np.random.seed(8)   \n",
    "final_merge.sample(10).to_csv(\"quality_check/final_merge_10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6ccb8a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASRS_30.to_csv('quality_check/asrs_30.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "774681c8-baf0-403c-9925-54ad9bdf4795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "739     f o was flying the acft and assigned a 060 deg...\n",
       "765     on taxi in at alt sbnd on ramp 3 right side no...\n",
       "768     mlg x landed rwy 9r and was told to hold short...\n",
       "811     under clear weather conditions landed rwy 9r a...\n",
       "848     the f o was lndg on rwy 27l at atl on 5 mi fin...\n",
       "883     taxiout was normal on tkof felt acft vibration...\n",
       "1051    atlanta apch ctlr was saturated radio calls we...\n",
       "Name: narrative, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ASRS_30.loc[(ASRS_30['tracon_code'] == 'ATL') & (ASRS_30['year'] == 1988) & (ASRS_30['month'] == 3)]['narrative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9e625672-4bd9-4d53-909a-0b898d7ff42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "test = ['mic', 'ctlr', 'hdg', 'capt', 'flt', 'abc', 'left', 'bbc', 'n', 'abeam']\n",
    "for x in test:\n",
    "    print(x in FAA_cleaned['acronym'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058fa064-66f4-4a9b-929f-8966647ca85f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
