{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "778cb5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\11099\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import preprocess_helper\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import enchant\n",
    "checker = enchant.Dict(\"en_US\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88eecde7",
   "metadata": {},
   "source": [
    "Use the processed ASRS output from `load_asrs()` in `preprocess_helper.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "392e00c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\aviation_integrated\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3357: DtypeWarning: Columns (8,9,11,12,14,15,19,20,28,29,30,31,32,33,34,38,39,40,41,42,46,50,53,54,56,57,58,59,60,64,65,70,71,72,74,75,80,81,82,86,88,93,94,95,104) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "# Dictionaries of acronym\n",
    "# CASA = pd.read_csv('dictionaries/CASA.csv')\n",
    "FAA = pd.read_csv('dictionaries/FAA.csv')\n",
    "NASA = pd.read_csv('dictionaries/nasa_abbr.csv')\n",
    "top_thirty = pd.read_csv('dictionaries/FAA Core Airports 2014.csv')\n",
    "\n",
    "# Limit to top thirty airports\n",
    "ASRS = preprocess_helper.load_asrs(load_saved=True)\n",
    "top_thirty_bool = ASRS['tracon_code'].isin(top_thirty['tracon_key'])\n",
    "ASRS_30 = ASRS[top_thirty_bool]\n",
    "\n",
    "# Accident and incident counts of FAA and NTSB\n",
    "acc_inc = pd.read_csv(r\"E:\\aviation_integrated\\results\\combined_vol_incident.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f8d161",
   "metadata": {},
   "source": [
    "`narrative` is the combination of `narrative_report1` and `narrative_report2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f29d3cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function used for counting the acronyms in ASRS data\n",
    "\n",
    "# Check if a word is spelled correctly \n",
    "def spell_check(word):\n",
    "    return checker.check(word)\n",
    "\n",
    "# Count the total occurrences of all dictionary acronyms in the text \n",
    "def count_total(word_count, dictionary):\n",
    "    total = 0\n",
    "    \n",
    "    for word in dictionary:\n",
    "        #if (word_count[word] != 0): print(word)\n",
    "        total += word_count[word]\n",
    "        \n",
    "    return total\n",
    "\n",
    "# Count the total unique occurrences of all dictionary acronyms in the text \n",
    "def count_unique(word_count, dictionary):\n",
    "    total = 0\n",
    "    \n",
    "    for word in dictionary:\n",
    "        if (word_count[word] != 0):\n",
    "            total += 1\n",
    "        \n",
    "    return total\n",
    "\n",
    "# Remove target symbols at both the start and the end of each string \n",
    "def strip_symbol(list_words, symbols):\n",
    "    return list(map(lambda x: x.strip(symbols), list_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c727bc3",
   "metadata": {},
   "source": [
    "Note: It seems Jimmy had already removed all symbols in the `clean_string_and_tokenize` function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f24c48",
   "metadata": {},
   "source": [
    "**Update in 01/04/2022: Discard CASA dictionary temporarily and stop testing spelling check.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2f26c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the field of acronyms\n",
    "\n",
    "# CASA['acronym'] = CASA['acronym'].str.strip().str.lower()\n",
    "# CASA['acronym'] = CASA['acronym'].str.replace(r'\\(.+\\)', '', regex=True)\n",
    "# CASA.drop_duplicates([\"acronym\"], inplace=True, keep='first')\n",
    "# CASA_cleaned = CASA[['acronym']]\n",
    "\n",
    "FAA['acronym'] = FAA['acronym'].str.strip().str.lower()\n",
    "FAA.drop_duplicates([\"acronym\"], inplace=True, keep='first')\n",
    "FAA_cleaned = FAA[['acronym']]\n",
    "\n",
    "NASA['acronym'] = NASA['acronym'].str.strip().str.lower()\n",
    "NASA.drop_duplicates([\"acronym\"], inplace=True, keep='first')\n",
    "NASA_cleaned = NASA[['acronym']]\n",
    "\n",
    "top_thirty['tracon_key'] = top_thirty['tracon_key'].str.strip().str.upper()\n",
    "top_thirty.drop_duplicates([\"tracon_key\"], inplace=True, keep='first')\n",
    "top_thirty_cleaned = top_thirty[['tracon_key']]\n",
    "\n",
    "# Remove stop words in the dictionaries\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# bool_index = CASA_cleaned.isin(stop_words)['acronym'].values\n",
    "# CASA_cleaned = CASA_cleaned[~bool_index]\n",
    "\n",
    "bool_index = FAA_cleaned.isin(stop_words)['acronym'].values\n",
    "FAA_cleaned = FAA_cleaned[~bool_index]\n",
    "\n",
    "bool_index = NASA_cleaned.isin(stop_words)['acronym'].values\n",
    "NASA_cleaned = NASA_cleaned[~bool_index]\n",
    "\n",
    "# Filter out the words passing the spelling check (OBSOLETE)\n",
    "# bool_index = np.array(list(map(spell_check, list(CASA_cleaned['acronym'].values))))\n",
    "# CASA_cleaned = CASA_cleaned[~bool_index]\n",
    "\n",
    "# bool_index = np.array(list(map(spell_check, list(FAA_cleaned['acronym'].values))))\n",
    "# FAA_cleaned = FAA_cleaned[~bool_index]\n",
    "\n",
    "# bool_index = np.array(list(map(spell_check, list(NASA_cleaned['acronym'].values))))\n",
    "# NASA_cleaned = NASA_cleaned[~bool_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcca3b7",
   "metadata": {},
   "source": [
    "**Update in 01/07/2022: Use the top 30 airports listed in `FAA Core Airports 2014.csv`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1569236c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrence of every distinct word in the text\n",
    "words = ASRS_30['narrative'].str.lower().str.split()\n",
    "words = words.apply(strip_symbol, symbols='{[(,:.')\n",
    "words_count = words.apply(Counter)\n",
    "acronyms = ASRS_30.loc[:, ['year', 'month', 'tracon_code', 'narrative', 'AtcAdvisoryMultCount']]\n",
    "acronyms['word_counter'] = words_count\n",
    "\n",
    "# Count the number of words\n",
    "acronyms['word_count'] = words.apply(len)\n",
    "acronyms['unique_word_count'] = words_count.apply(len)\n",
    "\n",
    "# Sum the occurences of acronyms in different dictionaries respectively\n",
    "# acronyms['CASA_total'] = acronyms['word_counter'].apply(count_occurrence, dictionary=CASA_cleaned['acronym'].values)\n",
    "# acronyms['CASA_unique'] = acronyms['word_counter'].apply(count_unique, dictionary=CASA_cleaned['acronym'].values)\n",
    "\n",
    "acronyms['FAA_total'] = acronyms['word_counter'].apply(count_total, dictionary=FAA_cleaned['acronym'].values)\n",
    "acronyms['FAA_unique'] = acronyms['word_counter'].apply(count_unique, dictionary=FAA_cleaned['acronym'].values)\n",
    "\n",
    "acronyms['NASA_total'] = acronyms['word_counter'].apply(count_total, dictionary=NASA_cleaned['acronym'].values)\n",
    "acronyms['NASA_unique'] = acronyms['word_counter'].apply(count_unique, dictionary=NASA_cleaned['acronym'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adce8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "acronyms.head()\n",
    "acronyms.to_csv(\"quality_check/full_count.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30761a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "acronyms.sort_values(['year', 'month', 'tracon_code'], inplace=True)\n",
    "acronyms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad072d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collapse by year-month-tracon and compute the sum and average per group\n",
    "num_obs = pd.DataFrame(acronyms.groupby(['year', 'month', 'tracon_code']).size(), columns = [\"num_obs\"])\n",
    "num_obs.reset_index(inplace = True)\n",
    "sum_count = acronyms.groupby(['year', 'month', 'tracon_code']).sum()\n",
    "sum_count.reset_index(inplace = True)\n",
    "avg_count = acronyms.groupby(['year', 'month', 'tracon_code']).mean()\n",
    "avg_count.reset_index(inplace = True)\n",
    "\n",
    "agg_count = num_obs.merge(sum_count, on=['year', 'month', 'tracon_code'])\n",
    "agg_count.rename(columns = {\"word_count\": \"word_count_sum\", \"unique_word_count\": \"unique_word_count_sum\",\n",
    "                            \"FAA_total\": \"FAA_total_sum\", \"FAA_unique\": \"FAA_unique_sum\",\n",
    "                            \"NASA_total\": \"NASA_total_sum\", \"NASA_unique\": \"NASA_unique_sum\",\n",
    "                            \"AtcAdvisoryMultCount\": \"AtcAdvisoryMultCount_sum\"}, inplace=True)\n",
    "agg_count = agg_count.merge(avg_count, on=['year', 'month', 'tracon_code'])\n",
    "agg_count.rename(columns = {\"word_count\": \"word_count_avg\", \"unique_word_count\": \"unique_word_count_avg\",\n",
    "                            \"FAA_total\": \"FAA_total_avg\", \"FAA_unique\": \"FAA_unique_avg\",\n",
    "                            \"NASA_total\": \"NASA_total_avg\", \"NASA_unique\": \"NASA_unique_avg\",\n",
    "                           \"AtcAdvisoryMultCount\": \"AtcAdvisoryMultCount_avg\", 'tracon_code': 'tracon'}, inplace=True)\n",
    "agg_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f92254",
   "metadata": {},
   "source": [
    "****\n",
    "## Create Master Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d231e289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tracon</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATL</td>\n",
       "      <td>1988</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL</td>\n",
       "      <td>1988</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATL</td>\n",
       "      <td>1988</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATL</td>\n",
       "      <td>1988</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATL</td>\n",
       "      <td>1988</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11515</th>\n",
       "      <td>TPA</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11516</th>\n",
       "      <td>TPA</td>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11517</th>\n",
       "      <td>TPA</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11518</th>\n",
       "      <td>TPA</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11519</th>\n",
       "      <td>TPA</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11520 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      tracon  year  month\n",
       "0        ATL  1988      1\n",
       "1        ATL  1988      2\n",
       "2        ATL  1988      3\n",
       "3        ATL  1988      4\n",
       "4        ATL  1988      5\n",
       "...      ...   ...    ...\n",
       "11515    TPA  2019      8\n",
       "11516    TPA  2019      9\n",
       "11517    TPA  2019     10\n",
       "11518    TPA  2019     11\n",
       "11519    TPA  2019     12\n",
       "\n",
       "[11520 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date = pd.date_range(start = '1/1/1988', end = '12/31/2019', freq = 'M')\n",
    "date_df = pd.DataFrame(data = {'year': date.year, 'month': date.month})\n",
    "master_key = top_thirty.merge(date_df, how = 'cross')\n",
    "master_key = master_key.drop('ATADS_Type', axis = 1)\n",
    "master_key = master_key.rename({'tracon_key': 'tracon'}, axis = 1)\n",
    "master_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45c8faaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_key.to_csv(\"quality_check/master_key.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae7d3a8",
   "metadata": {},
   "source": [
    "## Merge FAA/NTSB with master key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1861e98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit NTSB/FAA to top 30\n",
    "acc_inc_bool = acc_inc['airport_code'].isin(top_thirty['tracon_key'])\n",
    "acc_inc_30 = acc_inc.loc[acc_inc_bool]\n",
    "acc_inc_30 = acc_inc_30.drop(\"Unnamed: 0\", axis = 1)\n",
    "acc_inc_30 = acc_inc_30.rename({'airport_code': 'tracon'}, axis = 1)\n",
    "acc_inc_30.to_csv('quality_check/acc_inc_30.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6b406b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tracon</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>ntsb_incidents</th>\n",
       "      <th>ntsb_accidents</th>\n",
       "      <th>faa_incidents</th>\n",
       "      <th>faa_ntsb_overlap</th>\n",
       "      <th>NTSB_FAA_incidents_total</th>\n",
       "      <th>NTSB_FAA_incidents_total_nodups</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATL</td>\n",
       "      <td>1988</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL</td>\n",
       "      <td>1988</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATL</td>\n",
       "      <td>1988</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATL</td>\n",
       "      <td>1988</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATL</td>\n",
       "      <td>1988</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11515</th>\n",
       "      <td>TPA</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11516</th>\n",
       "      <td>TPA</td>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11517</th>\n",
       "      <td>TPA</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11518</th>\n",
       "      <td>TPA</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11519</th>\n",
       "      <td>TPA</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11520 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      tracon  year  month  ntsb_incidents  ntsb_accidents  faa_incidents  \\\n",
       "0        ATL  1988      1             0.0             0.0            1.0   \n",
       "1        ATL  1988      2             NaN             NaN            NaN   \n",
       "2        ATL  1988      3             1.0             0.0            4.0   \n",
       "3        ATL  1988      4             1.0             0.0            0.0   \n",
       "4        ATL  1988      5             0.0             2.0            0.0   \n",
       "...      ...   ...    ...             ...             ...            ...   \n",
       "11515    TPA  2019      8             0.0             1.0            0.0   \n",
       "11516    TPA  2019      9             0.0             0.0            2.0   \n",
       "11517    TPA  2019     10             NaN             NaN            NaN   \n",
       "11518    TPA  2019     11             NaN             NaN            NaN   \n",
       "11519    TPA  2019     12             NaN             NaN            NaN   \n",
       "\n",
       "       faa_ntsb_overlap  NTSB_FAA_incidents_total  \\\n",
       "0                   0.0                       1.0   \n",
       "1                   NaN                       NaN   \n",
       "2                   1.0                       5.0   \n",
       "3                   0.0                       1.0   \n",
       "4                   0.0                       2.0   \n",
       "...                 ...                       ...   \n",
       "11515               0.0                       1.0   \n",
       "11516               0.0                       2.0   \n",
       "11517               NaN                       NaN   \n",
       "11518               NaN                       NaN   \n",
       "11519               NaN                       NaN   \n",
       "\n",
       "       NTSB_FAA_incidents_total_nodups  \n",
       "0                                  1.0  \n",
       "1                                  NaN  \n",
       "2                                  4.0  \n",
       "3                                  1.0  \n",
       "4                                  2.0  \n",
       "...                                ...  \n",
       "11515                              1.0  \n",
       "11516                              2.0  \n",
       "11517                              NaN  \n",
       "11518                              NaN  \n",
       "11519                              NaN  \n",
       "\n",
       "[11520 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faa_ntsb_merge = master_key.merge(acc_inc_30, left_on=['tracon', 'year', 'month'], right_on=['tracon', 'year', 'month'], how='left')\n",
    "faa_ntsb_merge.to_csv('quality_check/merge_acc_inc.csv')\n",
    "faa_ntsb_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3cf6c5",
   "metadata": {},
   "source": [
    "Note: Perhaps mark the missing data with an indicator column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fe4e57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "faa_ntsb_merge = faa_ntsb_merge.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c5d94c",
   "metadata": {},
   "source": [
    "## Moving average of ASRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2b38c32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>tracon_code</th>\n",
       "      <th>narrative</th>\n",
       "      <th>AtcAdvisoryMultCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1988</td>\n",
       "      <td>1</td>\n",
       "      <td>ATL</td>\n",
       "      <td>apching the atl area a solid line of thunderst...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1988</td>\n",
       "      <td>1</td>\n",
       "      <td>ATL</td>\n",
       "      <td>my coplt and i mlg abc had just been clrd for ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1988</td>\n",
       "      <td>1</td>\n",
       "      <td>ATL</td>\n",
       "      <td>while dsnding into the atl area on the 024 deg...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1988</td>\n",
       "      <td>2</td>\n",
       "      <td>ATL</td>\n",
       "      <td>established on ils rwy 27l atl on a 12 mile fi...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1988</td>\n",
       "      <td>2</td>\n",
       "      <td>ATL</td>\n",
       "      <td>atl apch ctlr gave a late turn on vector which...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1988</td>\n",
       "      <td>2</td>\n",
       "      <td>ATL</td>\n",
       "      <td>departed atl at xx30 lcl on 2 fri 88 and lande...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1988</td>\n",
       "      <td>2</td>\n",
       "      <td>ATL</td>\n",
       "      <td>acft departed atc clred on new dep proc to 400...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1988</td>\n",
       "      <td>2</td>\n",
       "      <td>ATL</td>\n",
       "      <td>we were on clbout from rwy 27r in atl clred to...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1988</td>\n",
       "      <td>3</td>\n",
       "      <td>ATL</td>\n",
       "      <td>f o was flying the acft and assigned a 060 deg...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1988</td>\n",
       "      <td>3</td>\n",
       "      <td>ATL</td>\n",
       "      <td>on taxi in at alt sbnd on ramp 3 right side no...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month tracon_code                                          narrative  \\\n",
       "0  1988      1         ATL  apching the atl area a solid line of thunderst...   \n",
       "1  1988      1         ATL  my coplt and i mlg abc had just been clrd for ...   \n",
       "2  1988      1         ATL  while dsnding into the atl area on the 024 deg...   \n",
       "3  1988      2         ATL  established on ils rwy 27l atl on a 12 mile fi...   \n",
       "4  1988      2         ATL  atl apch ctlr gave a late turn on vector which...   \n",
       "5  1988      2         ATL  departed atl at xx30 lcl on 2 fri 88 and lande...   \n",
       "6  1988      2         ATL  acft departed atc clred on new dep proc to 400...   \n",
       "7  1988      2         ATL  we were on clbout from rwy 27r in atl clred to...   \n",
       "8  1988      3         ATL  f o was flying the acft and assigned a 060 deg...   \n",
       "9  1988      3         ATL  on taxi in at alt sbnd on ramp 3 right side no...   \n",
       "\n",
       "   AtcAdvisoryMultCount  \n",
       "0                   1.0  \n",
       "1                   1.0  \n",
       "2                   1.0  \n",
       "3                   1.0  \n",
       "4                   1.0  \n",
       "5                   1.0  \n",
       "6                   1.0  \n",
       "7                   1.0  \n",
       "8                   1.0  \n",
       "9                   1.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge ASRS with master key\n",
    "asrs_merge = master_key.merge(ASRS_30, left_on=['tracon', 'year', 'month'], right_on=['tracon_code', 'year', 'month'], how='left')\n",
    "asrs_merge = asrs_merge.loc[:, ['year', 'month', 'tracon_code', 'narrative', 'AtcAdvisoryMultCount']]\n",
    "asrs_merge['narrative'] = asrs_merge['narrative'].fillna('')\n",
    "asrs_merge = asrs_merge.fillna(0)\n",
    "asrs_merge.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46f6fdd4-2f5a-4695-b35d-d93e7265ee49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create moving average window \n",
    "window_len = 6\n",
    "lag = 2\n",
    "windows = asrs_merge.rolling(window = window_len, min_periods=window_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5d1d7d4-e132-46e8-962f-f46071a3b37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists used to store the values from the moving window\n",
    "num_word_sum = []\n",
    "num_word_avg = []\n",
    "num_unique_word_sum = []\n",
    "num_unique_word_avg = []\n",
    "FAA_total_sum = []\n",
    "FAA_total_avg = []\n",
    "FAA_unique_sum = []\n",
    "FAA_unique_avg = []\n",
    "NASA_total_sum = []\n",
    "NASA_total_avg = []\n",
    "NASA_unique_sum = []\n",
    "NASA_unique_avg = []\n",
    "AtcAdvisoryMultCount_sum = []\n",
    "AtcAdvisoryMultCount_avg = []\n",
    "\n",
    "\n",
    "for window in windows:\n",
    "    size = window.shape[0]\n",
    "    \n",
    "    # create a dictionary of counts of words\n",
    "    all_words = window['narrative'].str.cat(sep=' ')\n",
    "    all_words = all_words.lower().split()\n",
    "    all_words = [x.strip('{[(,:.') for x in all_words]\n",
    "    words_count = Counter(all_words)\n",
    "    \n",
    "    # number of words\n",
    "    num_word = len(all_words)\n",
    "    num_word_sum.append(num_word)\n",
    "    num_word_avg.append(num_word / size)\n",
    "    \n",
    "    # number of unique words\n",
    "    num_unique_word = len(words_count)\n",
    "    num_unique_word_sum.append(num_unique_word)\n",
    "    num_unique_word_avg.append(num_unique_word / size)\n",
    "    \n",
    "    # number of FAA acronyms\n",
    "    FAA_total = count_total(words_count, dictionary=FAA_cleaned['acronym'].values)\n",
    "    FAA_total_sum.append(FAA_total)\n",
    "    FAA_total_avg.append(FAA_total / size)\n",
    "    \n",
    "    # number of unique FAA acronyms\n",
    "    FAA_unique = count_unique(words_count, dictionary=FAA_cleaned['acronym'].values)\n",
    "    FAA_unique_sum.append(FAA_unique)\n",
    "    FAA_unique_avg.append(FAA_unique / size)\n",
    "    \n",
    "    # number of NASA acronyms\n",
    "    NASA_total = count_total(words_count, dictionary=NASA_cleaned['acronym'].values)\n",
    "    NASA_total_sum.append(NASA_total)\n",
    "    NASA_total_avg.append(NASA_total / size)\n",
    "    \n",
    "    # number of unique NASA acronyms\n",
    "    NASA_unique = count_unique(words_count, dictionary=NASA_cleaned['acronym'].values)\n",
    "    NASA_unique_sum.append(NASA_unique)\n",
    "    NASA_unique_avg.append(NASA_unique / size)\n",
    "    \n",
    "    # number of atcadvisory splits\n",
    "    num_splits = window['AtcAdvisoryMultCount'].sum()\n",
    "    AtcAdvisoryMultCount_sum.append(num_splits)\n",
    "    AtcAdvisoryMultCount_avg.append(num_splits / size)\n",
    "\n",
    "num_word_sum = np.array(num_word_sum)\n",
    "num_word_avg =  np.array(num_word_avg)\n",
    "num_unique_word_sum = np.array(num_unique_word_sum)\n",
    "num_unique_word_avg = np.array(num_unique_word_avg)\n",
    "FAA_total_sum = np.array(FAA_total_sum)\n",
    "FAA_total_avg = np.array(FAA_total_avg)\n",
    "FAA_unique_sum = np.array(FAA_unique_sum)\n",
    "FAA_unique_avg = np.array(FAA_unique_avg)\n",
    "NASA_total_sum = np.array(NASA_total_sum)\n",
    "NASA_total_avg = np.array(NASA_total_avg)\n",
    "NASA_unique_sum = np.array(NASA_unique_sum)\n",
    "NASA_unique_avg = np.array(NASA_unique_avg)\n",
    "AtcAdvisoryMultCount_sum = np.array(AtcAdvisoryMultCount_sum)\n",
    "AtcAdvisoryMultCount_avg = np.array(AtcAdvisoryMultCount_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4634a290",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>tracon_code</th>\n",
       "      <th>num_word_sum</th>\n",
       "      <th>num_word_avg</th>\n",
       "      <th>num_unique_word_sum</th>\n",
       "      <th>num_unique_word_avg</th>\n",
       "      <th>FAA_total_sum</th>\n",
       "      <th>FAA_total_avg</th>\n",
       "      <th>FAA_unique_sum</th>\n",
       "      <th>FAA_unique_avg</th>\n",
       "      <th>NASA_total_sum</th>\n",
       "      <th>NASA_total_avg</th>\n",
       "      <th>NASA_unique_sum</th>\n",
       "      <th>NASA_unique_avg</th>\n",
       "      <th>AtcAdvisoryMultCount_sum</th>\n",
       "      <th>AtcAdvisoryMultCount_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1988</td>\n",
       "      <td>1</td>\n",
       "      <td>ATL</td>\n",
       "      <td>200</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>107</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>26</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1988</td>\n",
       "      <td>1</td>\n",
       "      <td>ATL</td>\n",
       "      <td>874</td>\n",
       "      <td>437.000000</td>\n",
       "      <td>292</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>27</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>6</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>109</td>\n",
       "      <td>54.500000</td>\n",
       "      <td>35</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1988</td>\n",
       "      <td>1</td>\n",
       "      <td>ATL</td>\n",
       "      <td>1047</td>\n",
       "      <td>349.000000</td>\n",
       "      <td>343</td>\n",
       "      <td>114.333333</td>\n",
       "      <td>32</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>7</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>134</td>\n",
       "      <td>44.666667</td>\n",
       "      <td>46</td>\n",
       "      <td>15.333333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1988</td>\n",
       "      <td>2</td>\n",
       "      <td>ATL</td>\n",
       "      <td>1223</td>\n",
       "      <td>305.750000</td>\n",
       "      <td>408</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>49</td>\n",
       "      <td>12.250000</td>\n",
       "      <td>14</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>156</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>56</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1988</td>\n",
       "      <td>2</td>\n",
       "      <td>ATL</td>\n",
       "      <td>1757</td>\n",
       "      <td>351.400000</td>\n",
       "      <td>516</td>\n",
       "      <td>103.200000</td>\n",
       "      <td>74</td>\n",
       "      <td>14.800000</td>\n",
       "      <td>19</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>224</td>\n",
       "      <td>44.800000</td>\n",
       "      <td>69</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39635</th>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>16.333333</td>\n",
       "      <td>68</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39636</th>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>16.333333</td>\n",
       "      <td>68</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39637</th>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>16.333333</td>\n",
       "      <td>68</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39638</th>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>16.333333</td>\n",
       "      <td>68</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39639</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39640 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year  month tracon_code  num_word_sum  num_word_avg  \\\n",
       "0      1988      1         ATL           200    200.000000   \n",
       "1      1988      1         ATL           874    437.000000   \n",
       "2      1988      1         ATL          1047    349.000000   \n",
       "3      1988      2         ATL          1223    305.750000   \n",
       "4      1988      2         ATL          1757    351.400000   \n",
       "...     ...    ...         ...           ...           ...   \n",
       "39635  2019      8           0            98     16.333333   \n",
       "39636  2019      9           0            98     16.333333   \n",
       "39637  2019     10           0            98     16.333333   \n",
       "39638  2019     11           0            98     16.333333   \n",
       "39639  2019     12           0             0      0.000000   \n",
       "\n",
       "       num_unique_word_sum  num_unique_word_avg  FAA_total_sum  FAA_total_avg  \\\n",
       "0                      107           107.000000              7       7.000000   \n",
       "1                      292           146.000000             27      13.500000   \n",
       "2                      343           114.333333             32      10.666667   \n",
       "3                      408           102.000000             49      12.250000   \n",
       "4                      516           103.200000             74      14.800000   \n",
       "...                    ...                  ...            ...            ...   \n",
       "39635                   68            11.333333              1       0.166667   \n",
       "39636                   68            11.333333              1       0.166667   \n",
       "39637                   68            11.333333              1       0.166667   \n",
       "39638                   68            11.333333              1       0.166667   \n",
       "39639                    0             0.000000              0       0.000000   \n",
       "\n",
       "       FAA_unique_sum  FAA_unique_avg  NASA_total_sum  NASA_total_avg  \\\n",
       "0                   5        5.000000              26       26.000000   \n",
       "1                   6        3.000000             109       54.500000   \n",
       "2                   7        2.333333             134       44.666667   \n",
       "3                  14        3.500000             156       39.000000   \n",
       "4                  19        3.800000             224       44.800000   \n",
       "...               ...             ...             ...             ...   \n",
       "39635               1        0.166667               0        0.000000   \n",
       "39636               1        0.166667               0        0.000000   \n",
       "39637               1        0.166667               0        0.000000   \n",
       "39638               1        0.166667               0        0.000000   \n",
       "39639               0        0.000000               0        0.000000   \n",
       "\n",
       "       NASA_unique_sum  NASA_unique_avg  AtcAdvisoryMultCount_sum  \\\n",
       "0                   18        18.000000                       1.0   \n",
       "1                   35        17.500000                       2.0   \n",
       "2                   46        15.333333                       3.0   \n",
       "3                   56        14.000000                       4.0   \n",
       "4                   69        13.800000                       5.0   \n",
       "...                ...              ...                       ...   \n",
       "39635                0         0.000000                       1.0   \n",
       "39636                0         0.000000                       1.0   \n",
       "39637                0         0.000000                       1.0   \n",
       "39638                0         0.000000                       1.0   \n",
       "39639                0         0.000000                       0.0   \n",
       "\n",
       "       AtcAdvisoryMultCount_avg  \n",
       "0                      1.000000  \n",
       "1                      1.000000  \n",
       "2                      1.000000  \n",
       "3                      1.000000  \n",
       "4                      1.000000  \n",
       "...                         ...  \n",
       "39635                  0.166667  \n",
       "39636                  0.166667  \n",
       "39637                  0.166667  \n",
       "39638                  0.166667  \n",
       "39639                  0.000000  \n",
       "\n",
       "[39640 rows x 17 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asrs_moving = asrs_merge.drop(['narrative', 'AtcAdvisoryMultCount'], axis = 1)\n",
    "asrs_moving['num_word_sum'] = num_word_sum\n",
    "asrs_moving['num_word_avg'] = num_word_avg\n",
    "asrs_moving['num_unique_word_sum'] = num_unique_word_sum \n",
    "asrs_moving['num_unique_word_avg'] = num_unique_word_avg \n",
    "asrs_moving['FAA_total_sum'] = FAA_total_sum\n",
    "asrs_moving['FAA_total_avg'] = FAA_total_avg\n",
    "asrs_moving['FAA_unique_sum'] = FAA_unique_sum\n",
    "asrs_moving['FAA_unique_avg'] = FAA_unique_avg\n",
    "asrs_moving['NASA_total_sum'] = NASA_total_sum\n",
    "asrs_moving['NASA_total_avg'] = NASA_total_avg\n",
    "asrs_moving['NASA_unique_sum'] = NASA_unique_sum\n",
    "asrs_moving['NASA_unique_avg'] = NASA_unique_avg\n",
    "asrs_moving['AtcAdvisoryMultCount_sum'] = AtcAdvisoryMultCount_sum\n",
    "asrs_moving['AtcAdvisoryMultCount_avg'] = AtcAdvisoryMultCount_avg\n",
    "asrs_moving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0a56a47-ccee-41ab-8275-c1fe6e021d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "asrs_merge.to_csv(\"quality_check/asrs_merge.csv\")\n",
    "asrs_moving.to_csv(\"quality_check/asrs_moving.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da014866",
   "metadata": {},
   "source": [
    "****\n",
    "## Create moving average of ASRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93193e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "asrs_splits = [asrs_merge[asrs_merge['tracon'] == tracon] for tracon in top_thirty['tracon_key']] # can be optimized\n",
    "faa_ntsb_splits = [faa_ntsb_merge[faa_ntsb_merge['tracon'] == tracon] for tracon in top_thirty['tracon_key']] # can be optimized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcede47b",
   "metadata": {},
   "source": [
    "### Toy example: ATL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1f2e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATL = asrs_splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0751265c",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_len = 6\n",
    "lag = 2\n",
    "moving_avg = ATL.rolling(window_len, min_periods=window_len).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39c9d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATL.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c4ed80",
   "metadata": {},
   "source": [
    "1. Select columns to average and sum. No {year, month}\n",
    "2. First get the window of the text, then do the manuplication and computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e015c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_avg.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68663b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATL.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bac3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_avg.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30bfd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATL.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15677ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_avg = ATL.rolling(window_len, min_periods=window_len).sum()\n",
    "empty_row_df = pd.DataFrame(data = [pd.Series(index=ATL.columns) for _ in range(lag)])\n",
    "empty_row_df = empty_row_df.drop('tracon', axis = 1)\n",
    "moving_avg = pd.concat([empty_row_df, moving_avg])\n",
    "moving_avg = moving_avg.drop(['year', 'month'], axis = 1)\n",
    "moving_avg = moving_avg.reset_index().drop('index', axis = 1)\n",
    "merge_df = pd.concat([faa_ntsb_splits[0], moving_avg], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2526f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9060f990",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59a3a4e",
   "metadata": {},
   "source": [
    "### Entire pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd8b746",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "window_len = 6\n",
    "lag = 1\n",
    "\n",
    "asrs_splits = [asrs_merge[asrs_merge['tracon'] == tracon] for tracon in top_thirty['tracon_key']] # can be optimized\n",
    "faa_ntsb_splits = [faa_ntsb_merge[faa_ntsb_merge['tracon'] == tracon] for tracon in top_thirty['tracon_key']] # can be optimized\n",
    "final = []\n",
    "\n",
    "for i in range(len(asrs_splits)):\n",
    "    asrs = asrs_splits[i].reset_index().drop('index', axis = 1)\n",
    "    faa_ntsb = faa_ntsb_splits[i].reset_index().drop('index', axis = 1)\n",
    "    \n",
    "    # compute moving average of ASRS \n",
    "    mov_avg = asrs.rolling(window_len, min_periods=window_len).mean()\n",
    "    \n",
    "    # insert empty rows at the beginning for lagging\n",
    "    empty_row_df = pd.DataFrame(data = [pd.Series(index=asrs.columns) for _ in range(lag)])\n",
    "    empty_row_df = empty_row_df.drop('tracon', axis = 1)   \n",
    "    \n",
    "    # merge the moving averages of ASRS with FAA+NTSB \n",
    "    moving_avg = pd.concat([empty_row_df, mov_avg])\n",
    "    moving_avg = moving_avg.drop(['year', 'month'], axis = 1)\n",
    "    moving_avg = moving_avg.reset_index().drop('index', axis = 1)\n",
    "    merge_df = pd.concat([faa_ntsb, moving_avg], axis = 1)\n",
    "    final.append(merge_df)\n",
    "\n",
    "final_df = pd.concat(final).reset_index().drop('index', axis = 1)\n",
    "final_df.to_csv('quality_check/final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6169ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4cf50d",
   "metadata": {},
   "source": [
    "# Quality check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86142ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(\"quality_check\")\n",
    "except OSError as error:\n",
    "    print(error)\n",
    "\n",
    "np.random.seed(8)   \n",
    "final_merge.sample(10).to_csv(\"quality_check/final_merge_10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccb8a75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
