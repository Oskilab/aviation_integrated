{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "778cb5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\11099\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import preprocess_helper\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import enchant\n",
    "checker = enchant.Dict(\"en_US\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88eecde7",
   "metadata": {},
   "source": [
    "Use the processed ASRS output from `load_asrs()` in `preprocess_helper.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "392e00c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\aviation_integrated\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3357: DtypeWarning: Columns (8,9,11,12,14,15,19,20,28,29,30,31,32,33,34,38,39,40,41,42,46,50,53,54,56,57,58,59,60,64,65,70,71,72,74,75,80,81,82,86,88,93,94,95,104) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "# Dictionaries of acronym\n",
    "# CASA = pd.read_csv('dictionaries/CASA.csv')\n",
    "FAA = pd.read_csv('dictionaries/FAA.csv')\n",
    "NASA = pd.read_csv('dictionaries/nasa_abbr.csv')\n",
    "top_thirty = pd.read_csv('dictionaries/FAA Core Airports 2014.csv')\n",
    "\n",
    "# Limit to top thirty airports\n",
    "ASRS = preprocess_helper.load_asrs(load_saved=True)\n",
    "top_thirty_bool = ASRS['tracon_code'].isin(top_thirty['tracon_key'])\n",
    "ASRS_30 = ASRS[top_thirty_bool]\n",
    "\n",
    "# Accident and incident counts of FAA and NTSB\n",
    "acc_inc = pd.read_csv(r\"E:\\aviation_integrated\\results\\combined_vol_incident.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f8d161",
   "metadata": {},
   "source": [
    "`narrative` is the combination of `narrative_report1` and `narrative_report2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f29d3cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function used for counting the acronyms in ASRS data\n",
    "\n",
    "# Check if a word is spelled correctly \n",
    "def spell_check(word):\n",
    "    return checker.check(word)\n",
    "\n",
    "# Count the total occurrences of all dictionary acronyms in the text \n",
    "def count_total(word_count, dictionary):\n",
    "    total = 0\n",
    "    \n",
    "    for word in dictionary:\n",
    "        #if (word_count[word] != 0): print(word)\n",
    "        total += word_count[word]\n",
    "        \n",
    "    return total\n",
    "\n",
    "# Count the total unique occurrences of all dictionary acronyms in the text \n",
    "def count_unique(word_count, dictionary):\n",
    "    total = 0\n",
    "    \n",
    "    for word in dictionary:\n",
    "        if (word_count[word] != 0):\n",
    "            total += 1\n",
    "        \n",
    "    return total\n",
    "\n",
    "# Remove target symbols at both the start and the end of each string \n",
    "def strip_symbol(list_words, symbols):\n",
    "    return list(map(lambda x: x.strip(symbols), list_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c727bc3",
   "metadata": {},
   "source": [
    "Note: It seems Jimmy had already removed all symbols in the `clean_string_and_tokenize` function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f24c48",
   "metadata": {},
   "source": [
    "**Update in 01/04/2022: Discard CASA dictionary temporarily and stop testing spelling check.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2f26c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the field of acronyms\n",
    "\n",
    "# CASA['acronym'] = CASA['acronym'].str.strip().str.lower()\n",
    "# CASA['acronym'] = CASA['acronym'].str.replace(r'\\(.+\\)', '', regex=True)\n",
    "# CASA.drop_duplicates([\"acronym\"], inplace=True, keep='first')\n",
    "# CASA_cleaned = CASA[['acronym']]\n",
    "\n",
    "FAA['acronym'] = FAA['acronym'].str.strip().str.lower()\n",
    "FAA.drop_duplicates([\"acronym\"], inplace=True, keep='first')\n",
    "FAA_cleaned = FAA[['acronym']]\n",
    "\n",
    "NASA['acronym'] = NASA['acronym'].str.strip().str.lower()\n",
    "NASA.drop_duplicates([\"acronym\"], inplace=True, keep='first')\n",
    "NASA_cleaned = NASA[['acronym']]\n",
    "\n",
    "top_thirty['tracon_key'] = top_thirty['tracon_key'].str.strip().str.upper()\n",
    "top_thirty.drop_duplicates([\"tracon_key\"], inplace=True, keep='first')\n",
    "top_thirty_cleaned = top_thirty[['tracon_key']]\n",
    "\n",
    "# Remove stop words in the dictionaries\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# bool_index = CASA_cleaned.isin(stop_words)['acronym'].values\n",
    "# CASA_cleaned = CASA_cleaned[~bool_index]\n",
    "\n",
    "bool_index = FAA_cleaned.isin(stop_words)['acronym'].values\n",
    "FAA_cleaned = FAA_cleaned[~bool_index]\n",
    "\n",
    "bool_index = NASA_cleaned.isin(stop_words)['acronym'].values\n",
    "NASA_cleaned = NASA_cleaned[~bool_index]\n",
    "\n",
    "# Filter out the words passing the spelling check (OBSOLETE)\n",
    "# bool_index = np.array(list(map(spell_check, list(CASA_cleaned['acronym'].values))))\n",
    "# CASA_cleaned = CASA_cleaned[~bool_index]\n",
    "\n",
    "# bool_index = np.array(list(map(spell_check, list(FAA_cleaned['acronym'].values))))\n",
    "# FAA_cleaned = FAA_cleaned[~bool_index]\n",
    "\n",
    "# bool_index = np.array(list(map(spell_check, list(NASA_cleaned['acronym'].values))))\n",
    "# NASA_cleaned = NASA_cleaned[~bool_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcca3b7",
   "metadata": {},
   "source": [
    "**Update in 01/07/2022: Use the top 30 airports listed in `FAA Core Airports 2014.csv`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f92254",
   "metadata": {},
   "source": [
    "****\n",
    "## Create Master Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d231e289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tracon</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATL</td>\n",
       "      <td>1988</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL</td>\n",
       "      <td>1988</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATL</td>\n",
       "      <td>1988</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATL</td>\n",
       "      <td>1988</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATL</td>\n",
       "      <td>1988</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11515</th>\n",
       "      <td>TPA</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11516</th>\n",
       "      <td>TPA</td>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11517</th>\n",
       "      <td>TPA</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11518</th>\n",
       "      <td>TPA</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11519</th>\n",
       "      <td>TPA</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11520 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      tracon  year  month\n",
       "0        ATL  1988      1\n",
       "1        ATL  1988      2\n",
       "2        ATL  1988      3\n",
       "3        ATL  1988      4\n",
       "4        ATL  1988      5\n",
       "...      ...   ...    ...\n",
       "11515    TPA  2019      8\n",
       "11516    TPA  2019      9\n",
       "11517    TPA  2019     10\n",
       "11518    TPA  2019     11\n",
       "11519    TPA  2019     12\n",
       "\n",
       "[11520 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date = pd.date_range(start = '1/1/1988', end = '12/31/2019', freq = 'M')\n",
    "date_df = pd.DataFrame(data = {'year': date.year, 'month': date.month})\n",
    "master_key = top_thirty.merge(date_df, how = 'cross')\n",
    "master_key = master_key.drop('ATADS_Type', axis = 1)\n",
    "master_key = master_key.rename({'tracon_key': 'tracon'}, axis = 1)\n",
    "master_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45c8faaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_key.to_csv(\"quality_check/master_key.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae7d3a8",
   "metadata": {},
   "source": [
    "## Merge FAA/NTSB with master key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1861e98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit NTSB/FAA to top 30\n",
    "acc_inc_bool = acc_inc['airport_code'].isin(top_thirty['tracon_key'])\n",
    "acc_inc_30 = acc_inc.loc[acc_inc_bool]\n",
    "acc_inc_30 = acc_inc_30.drop(\"Unnamed: 0\", axis = 1)\n",
    "acc_inc_30 = acc_inc_30.rename({'airport_code': 'tracon'}, axis = 1)\n",
    "acc_inc_30.to_csv('quality_check/acc_inc_30.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6b406b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tracon</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>ntsb_incidents</th>\n",
       "      <th>ntsb_accidents</th>\n",
       "      <th>faa_incidents</th>\n",
       "      <th>faa_ntsb_overlap</th>\n",
       "      <th>NTSB_FAA_incidents_total</th>\n",
       "      <th>NTSB_FAA_incidents_total_nodups</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATL</td>\n",
       "      <td>1988</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL</td>\n",
       "      <td>1988</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATL</td>\n",
       "      <td>1988</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATL</td>\n",
       "      <td>1988</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATL</td>\n",
       "      <td>1988</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11515</th>\n",
       "      <td>TPA</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11516</th>\n",
       "      <td>TPA</td>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11517</th>\n",
       "      <td>TPA</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11518</th>\n",
       "      <td>TPA</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11519</th>\n",
       "      <td>TPA</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11520 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      tracon  year  month  ntsb_incidents  ntsb_accidents  faa_incidents  \\\n",
       "0        ATL  1988      1             0.0             0.0            1.0   \n",
       "1        ATL  1988      2             NaN             NaN            NaN   \n",
       "2        ATL  1988      3             1.0             0.0            4.0   \n",
       "3        ATL  1988      4             1.0             0.0            0.0   \n",
       "4        ATL  1988      5             0.0             2.0            0.0   \n",
       "...      ...   ...    ...             ...             ...            ...   \n",
       "11515    TPA  2019      8             0.0             1.0            0.0   \n",
       "11516    TPA  2019      9             0.0             0.0            2.0   \n",
       "11517    TPA  2019     10             NaN             NaN            NaN   \n",
       "11518    TPA  2019     11             NaN             NaN            NaN   \n",
       "11519    TPA  2019     12             NaN             NaN            NaN   \n",
       "\n",
       "       faa_ntsb_overlap  NTSB_FAA_incidents_total  \\\n",
       "0                   0.0                       1.0   \n",
       "1                   NaN                       NaN   \n",
       "2                   1.0                       5.0   \n",
       "3                   0.0                       1.0   \n",
       "4                   0.0                       2.0   \n",
       "...                 ...                       ...   \n",
       "11515               0.0                       1.0   \n",
       "11516               0.0                       2.0   \n",
       "11517               NaN                       NaN   \n",
       "11518               NaN                       NaN   \n",
       "11519               NaN                       NaN   \n",
       "\n",
       "       NTSB_FAA_incidents_total_nodups  \n",
       "0                                  1.0  \n",
       "1                                  NaN  \n",
       "2                                  4.0  \n",
       "3                                  1.0  \n",
       "4                                  2.0  \n",
       "...                                ...  \n",
       "11515                              1.0  \n",
       "11516                              2.0  \n",
       "11517                              NaN  \n",
       "11518                              NaN  \n",
       "11519                              NaN  \n",
       "\n",
       "[11520 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faa_ntsb_merge = master_key.merge(acc_inc_30, left_on=['tracon', 'year', 'month'], right_on=['tracon', 'year', 'month'], how='left')\n",
    "faa_ntsb_merge.to_csv('quality_check/merge_acc_inc.csv')\n",
    "faa_ntsb_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3cf6c5",
   "metadata": {},
   "source": [
    "Note: Perhaps mark the missing data with an indicator column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fe4e57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "faa_ntsb_merge = faa_ntsb_merge.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c5d94c",
   "metadata": {},
   "source": [
    "## Moving average of ASRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "014a20a8-0309-4735-9a49-577b9467480a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collapse ASRS by [year, month, tracon_code]\n",
    "asrs_collapse = ASRS_30.groupby(['year', 'month', 'tracon_code'])[['narrative']].agg(lambda x: x.str.cat(sep=' ')).reset_index()\n",
    "asrs_collapse['num_obs'] = ASRS_30.groupby(['year', 'month', 'tracon_code']).size().values\n",
    "asrs_collapse['AtcAdvisoryMultCount'] = ASRS_30.groupby(['year', 'month', 'tracon_code'])['AtcAdvisoryMultCount'].sum().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "35604fbf-e1f8-4d56-9809-727286f88923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>tracon_code</th>\n",
       "      <th>narrative</th>\n",
       "      <th>num_obs</th>\n",
       "      <th>AtcAdvisoryMultCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1988.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>apching the atl area a solid line of thunderst...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1988.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BOS</td>\n",
       "      <td>atis and arpt rwy condition broadcast was givi...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1988.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CLT</td>\n",
       "      <td>we were on a radar vector by clt apch ctl on a...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1988.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DCA</td>\n",
       "      <td>i departed bwi vfr and dep ctl clred me on cou...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1988.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DEN</td>\n",
       "      <td>a vfr flt being conducted under far part 91 wa...</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  month tracon_code  \\\n",
       "0  1988.0    1.0         ATL   \n",
       "1  1988.0    1.0         BOS   \n",
       "2  1988.0    1.0         CLT   \n",
       "3  1988.0    1.0         DCA   \n",
       "4  1988.0    1.0         DEN   \n",
       "\n",
       "                                           narrative  num_obs  \\\n",
       "0  apching the atl area a solid line of thunderst...        3   \n",
       "1  atis and arpt rwy condition broadcast was givi...        5   \n",
       "2  we were on a radar vector by clt apch ctl on a...        1   \n",
       "3  i departed bwi vfr and dep ctl clred me on cou...        5   \n",
       "4  a vfr flt being conducted under far part 91 wa...        7   \n",
       "\n",
       "   AtcAdvisoryMultCount  \n",
       "0                     3  \n",
       "1                     5  \n",
       "2                     1  \n",
       "3                     6  \n",
       "4                     8  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asrs_collapse.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b2b38c32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>tracon</th>\n",
       "      <th>narrative</th>\n",
       "      <th>AtcAdvisoryMultCount</th>\n",
       "      <th>num_obs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1988</td>\n",
       "      <td>1</td>\n",
       "      <td>ATL</td>\n",
       "      <td>apching the atl area a solid line of thunderst...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1988</td>\n",
       "      <td>2</td>\n",
       "      <td>ATL</td>\n",
       "      <td>established on ils rwy 27l atl on a 12 mile fi...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1988</td>\n",
       "      <td>3</td>\n",
       "      <td>ATL</td>\n",
       "      <td>f o was flying the acft and assigned a 060 deg...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1988</td>\n",
       "      <td>4</td>\n",
       "      <td>ATL</td>\n",
       "      <td>tca was inadvertently entered at 11500 in uppe...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1988</td>\n",
       "      <td>5</td>\n",
       "      <td>ATL</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1988</td>\n",
       "      <td>6</td>\n",
       "      <td>ATL</td>\n",
       "      <td>while being vectored for apch to rwy 9r atc di...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1988</td>\n",
       "      <td>7</td>\n",
       "      <td>ATL</td>\n",
       "      <td>during enrte portion of flt we were assigned a...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1988</td>\n",
       "      <td>8</td>\n",
       "      <td>ATL</td>\n",
       "      <td>at about 200 agl on final apch to rwy 27l at a...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1988</td>\n",
       "      <td>9</td>\n",
       "      <td>ATL</td>\n",
       "      <td>mlg x was dsnded to 12000 mlg x read back 1000...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1988</td>\n",
       "      <td>10</td>\n",
       "      <td>ATL</td>\n",
       "      <td>at 13000 level flt 250 kts i asked the f o to ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month tracon                                          narrative  \\\n",
       "0  1988      1    ATL  apching the atl area a solid line of thunderst...   \n",
       "1  1988      2    ATL  established on ils rwy 27l atl on a 12 mile fi...   \n",
       "2  1988      3    ATL  f o was flying the acft and assigned a 060 deg...   \n",
       "3  1988      4    ATL  tca was inadvertently entered at 11500 in uppe...   \n",
       "4  1988      5    ATL                                                      \n",
       "5  1988      6    ATL  while being vectored for apch to rwy 9r atc di...   \n",
       "6  1988      7    ATL  during enrte portion of flt we were assigned a...   \n",
       "7  1988      8    ATL  at about 200 agl on final apch to rwy 27l at a...   \n",
       "8  1988      9    ATL  mlg x was dsnded to 12000 mlg x read back 1000...   \n",
       "9  1988     10    ATL  at 13000 level flt 250 kts i asked the f o to ...   \n",
       "\n",
       "   AtcAdvisoryMultCount  num_obs  \n",
       "0                   3.0      3.0  \n",
       "1                   5.0      5.0  \n",
       "2                   7.0      7.0  \n",
       "3                   1.0      1.0  \n",
       "4                   0.0      0.0  \n",
       "5                   5.0      5.0  \n",
       "6                   5.0      3.0  \n",
       "7                  11.0      8.0  \n",
       "8                   6.0      5.0  \n",
       "9                   5.0      4.0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge ASRS with master key\n",
    "asrs_merge = master_key.merge(asrs_collapse, left_on=['tracon', 'year', 'month'], right_on=['tracon_code', 'year', 'month'], how='left')\n",
    "asrs_merge = asrs_merge.loc[:, ['year', 'month', 'tracon', 'narrative', 'AtcAdvisoryMultCount', 'num_obs']]\n",
    "asrs_merge['narrative'] = asrs_merge['narrative'].fillna('')\n",
    "asrs_merge = asrs_merge.fillna(0)\n",
    "asrs_merge.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46f6fdd4-2f5a-4695-b35d-d93e7265ee49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create moving average window \n",
    "window_len = 6\n",
    "lag = 2\n",
    "windows = asrs_merge.rolling(window = window_len, min_periods=window_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3665a097-b256-47f9-ba8a-048ce75170c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:/Anaconda/envs/aviation_integrated/Library/bin/xpython:118: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "D:/Anaconda/envs/aviation_integrated/Library/bin/xpython:50: RuntimeWarning: invalid value encountered in double_scalars\n",
      "D:/Anaconda/envs/aviation_integrated/Library/bin/xpython:55: RuntimeWarning: invalid value encountered in double_scalars\n",
      "D:/Anaconda/envs/aviation_integrated/Library/bin/xpython:60: RuntimeWarning: invalid value encountered in double_scalars\n",
      "D:/Anaconda/envs/aviation_integrated/Library/bin/xpython:65: RuntimeWarning: invalid value encountered in double_scalars\n",
      "D:/Anaconda/envs/aviation_integrated/Library/bin/xpython:70: RuntimeWarning: invalid value encountered in double_scalars\n",
      "D:/Anaconda/envs/aviation_integrated/Library/bin/xpython:75: RuntimeWarning: invalid value encountered in double_scalars\n",
      "D:/Anaconda/envs/aviation_integrated/Library/bin/xpython:80: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "window_len = 6\n",
    "lag = 1\n",
    "\n",
    "asrs_splits = [asrs_merge[asrs_merge['tracon'] == tracon] for tracon in top_thirty['tracon_key']] # can be optimized\n",
    "faa_ntsb_splits = [faa_ntsb_merge[faa_ntsb_merge['tracon'] == tracon] for tracon in top_thirty['tracon_key']] # can be optimized\n",
    "final = []\n",
    "\n",
    "for i in range(len(asrs_splits)):\n",
    "    asrs = asrs_splits[i].reset_index().drop('index', axis = 1)\n",
    "    faa_ntsb = faa_ntsb_splits[i].reset_index().drop('index', axis = 1)\n",
    "    \n",
    "    # compute moving average of ASRS \n",
    "    windows = asrs.rolling(window = window_len, min_periods=window_len)\n",
    "    num_obs_sum = []\n",
    "    num_obs_avg = []\n",
    "    num_word_sum = []\n",
    "    num_word_avg = []\n",
    "    num_unique_word_sum = []\n",
    "    num_unique_word_avg = []\n",
    "    FAA_total_sum = []\n",
    "    FAA_total_avg = []\n",
    "    FAA_unique_sum = []\n",
    "    FAA_unique_avg = []\n",
    "    NASA_total_sum = []\n",
    "    NASA_total_avg = []\n",
    "    NASA_unique_sum = []\n",
    "    NASA_unique_avg = []\n",
    "    AtcAdvisoryMultCount_sum = []\n",
    "    AtcAdvisoryMultCount_avg = []\n",
    "\n",
    "\n",
    "    for window in windows:\n",
    "        size = window.shape[0]\n",
    "\n",
    "        # create a dictionary of counts of words\n",
    "        all_words = window['narrative'].str.cat(sep=' ')\n",
    "        all_words = all_words.lower().split()\n",
    "        all_words = [x.strip('{[(,:.') for x in all_words]\n",
    "        words_count = Counter(all_words)\n",
    "        \n",
    "        # number of observations\n",
    "        num_obs = window['num_obs'].sum()\n",
    "        total_obs = num_obs * size\n",
    "        num_obs_sum.append(num_obs)\n",
    "        num_obs_avg.append(num_obs / size)\n",
    "        \n",
    "        # number of words\n",
    "        num_word = len(all_words)\n",
    "        num_word_sum.append(num_word)\n",
    "        num_word_avg.append(num_word / total_obs)\n",
    "\n",
    "        # number of unique words\n",
    "        num_unique_word = len(words_count)\n",
    "        num_unique_word_sum.append(num_unique_word)\n",
    "        num_unique_word_avg.append(num_unique_word / total_obs)\n",
    "\n",
    "        # number of FAA acronyms\n",
    "        FAA_total = count_total(words_count, dictionary=FAA_cleaned['acronym'].values)\n",
    "        FAA_total_sum.append(FAA_total)\n",
    "        FAA_total_avg.append(FAA_total / total_obs)\n",
    "\n",
    "        # number of unique FAA acronyms\n",
    "        FAA_unique = count_unique(words_count, dictionary=FAA_cleaned['acronym'].values)\n",
    "        FAA_unique_sum.append(FAA_unique)\n",
    "        FAA_unique_avg.append(FAA_unique / total_obs)\n",
    "\n",
    "        # number of NASA acronyms\n",
    "        NASA_total = count_total(words_count, dictionary=NASA_cleaned['acronym'].values)\n",
    "        NASA_total_sum.append(NASA_total)\n",
    "        NASA_total_avg.append(NASA_total / total_obs)\n",
    "\n",
    "        # number of unique NASA acronyms\n",
    "        NASA_unique = count_unique(words_count, dictionary=NASA_cleaned['acronym'].values)\n",
    "        NASA_unique_sum.append(NASA_unique)\n",
    "        NASA_unique_avg.append(NASA_unique / total_obs)\n",
    "\n",
    "        # number of atcadvisory splits\n",
    "        num_splits = window['AtcAdvisoryMultCount'].sum()\n",
    "        AtcAdvisoryMultCount_sum.append(num_splits)\n",
    "        AtcAdvisoryMultCount_avg.append(num_splits / total_obs)\n",
    "\n",
    "    num_word_sum = np.array(num_word_sum)\n",
    "    num_word_avg =  np.array(num_word_avg)\n",
    "    num_unique_word_sum = np.array(num_unique_word_sum)\n",
    "    num_unique_word_avg = np.array(num_unique_word_avg)\n",
    "    FAA_total_sum = np.array(FAA_total_sum)\n",
    "    FAA_total_avg = np.array(FAA_total_avg)\n",
    "    FAA_unique_sum = np.array(FAA_unique_sum)\n",
    "    FAA_unique_avg = np.array(FAA_unique_avg)\n",
    "    NASA_total_sum = np.array(NASA_total_sum)\n",
    "    NASA_total_avg = np.array(NASA_total_avg)\n",
    "    NASA_unique_sum = np.array(NASA_unique_sum)\n",
    "    NASA_unique_avg = np.array(NASA_unique_avg)\n",
    "    AtcAdvisoryMultCount_sum = np.array(AtcAdvisoryMultCount_sum)\n",
    "    AtcAdvisoryMultCount_avg = np.array(AtcAdvisoryMultCount_avg)\n",
    "    num_obs_sum = np.array(num_obs_sum)\n",
    "    num_obs_avg = np.array(num_obs_avg)\n",
    "    \n",
    "    asrs_moving = asrs.drop(['narrative', 'AtcAdvisoryMultCount'], axis = 1)\n",
    "    asrs_moving['num_obs_sum'] = num_obs_sum\n",
    "    asrs_moving['num_obs_avg'] = num_obs_avg\n",
    "    asrs_moving['num_word_sum'] = num_word_sum\n",
    "    asrs_moving['num_word_avg'] = num_word_avg\n",
    "    asrs_moving['num_unique_word_sum'] = num_unique_word_sum \n",
    "    asrs_moving['num_unique_word_avg'] = num_unique_word_avg \n",
    "    asrs_moving['FAA_total_sum'] = FAA_total_sum\n",
    "    asrs_moving['FAA_total_avg'] = FAA_total_avg\n",
    "    asrs_moving['FAA_unique_sum'] = FAA_unique_sum\n",
    "    asrs_moving['FAA_unique_avg'] = FAA_unique_avg\n",
    "    asrs_moving['NASA_total_sum'] = NASA_total_sum\n",
    "    asrs_moving['NASA_total_avg'] = NASA_total_avg\n",
    "    asrs_moving['NASA_unique_sum'] = NASA_unique_sum\n",
    "    asrs_moving['NASA_unique_avg'] = NASA_unique_avg\n",
    "    asrs_moving['AtcAdvisoryMultCount_sum'] = AtcAdvisoryMultCount_sum\n",
    "    asrs_moving['AtcAdvisoryMultCount_avg'] = AtcAdvisoryMultCount_avg\n",
    "    \n",
    "    # insert empty rows at the beginning for lagging\n",
    "    empty_row_df = pd.DataFrame(data = [pd.Series(index=asrs.columns) for _ in range(lag)])\n",
    "    empty_row_df = empty_row_df.drop('tracon', axis = 1)   \n",
    "    \n",
    "    # merge the moving averages of ASRS with FAA+NTSB \n",
    "    asrs_moving = pd.concat([empty_row_df, asrs_moving])\n",
    "    asrs_moving = asrs_moving.drop(['year', 'month', 'tracon'], axis = 1)\n",
    "    asrs_moving = asrs_moving.reset_index().drop('index', axis = 1)\n",
    "    merge_df = pd.concat([faa_ntsb, asrs_moving], axis = 1)\n",
    "    final.append(merge_df)\n",
    "\n",
    "final_df = pd.concat(final).reset_index().drop(['index', 'AtcAdvisoryMultCount', 'narrative'], axis = 1)\n",
    "final_df.to_csv('quality_check/final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0a56a47-ccee-41ab-8275-c1fe6e021d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "asrs_merge.to_csv(\"quality_check/asrs_merge.csv\")\n",
    "asrs_moving.to_csv(\"quality_check/asrs_moving.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da014866",
   "metadata": {},
   "source": [
    "****\n",
    "## Create moving average of ASRS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4cf50d",
   "metadata": {},
   "source": [
    "# Quality check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86142ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(\"quality_check\")\n",
    "except OSError as error:\n",
    "    print(error)\n",
    "\n",
    "np.random.seed(8)   \n",
    "final_merge.sample(10).to_csv(\"quality_check/final_merge_10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccb8a75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
